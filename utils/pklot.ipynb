{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"pklot.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"umrrAs6FJhEp"},"source":["# **0. Imports**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9o1WZnmuhX5E","executionInfo":{"status":"ok","timestamp":1631660242793,"user_tz":300,"elapsed":122,"user":{"displayName":"Jorge Cervera Perez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14520205137583916864"}},"outputId":"5e739193-f27e-47b2-ab24-7866a3f1a1c5"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"9JzjGlCm4p4X","executionInfo":{"status":"ok","timestamp":1631660245204,"user_tz":300,"elapsed":2292,"user":{"displayName":"Jorge Cervera Perez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14520205137583916864"}}},"source":["import tensorflow as tf\n","import keras\n","from keras.models import Model\n","from keras.layers import Dense, Dropout, Activation, Flatten, Input\n","from tensorflow.keras.applications.resnet50 import ResNet50\n","from keras.callbacks import ModelCheckpoint\n","\n","import pandas as pandas\n","import numpy as np\n","from keras.preprocessing.image import img_to_array\n","from keras.preprocessing.image import load_img\n","import matplotlib.pyplot as plt"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8Zrrazr7JQzx"},"source":["# **1. Hyperparameters**"]},{"cell_type":"code","metadata":{"id":"z2OJxpH74mHm","executionInfo":{"status":"ok","timestamp":1631660245206,"user_tz":300,"elapsed":16,"user":{"displayName":"Jorge Cervera Perez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14520205137583916864"}}},"source":["img_height = 200\n","img_width = 267\n","img_channels = 3\n","\n","learning_rate = 1e-7\n","batch_size = 5\n","\n","route = \"/content/drive/MyDrive/TFM/data/merged_data\" \n","#route = \"/content/drive/MyDrive/TFM/data_reduced\" \n","\n","database_len_train = 25195 #580       #total: 25196\n","database_len_val = 3140 #100          #total: 3148\n","database_len_test = 3140              #total: 3148\n","\n","nb_epoch = 1\n","\n","# Number of batches\n","steps_per_epoch = np.ceil( database_len_train / batch_size )\n","validation_steps = np.ceil( database_len_val / batch_size )\n","test_steps = np.ceil( database_len_test / batch_size )"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fpdR-mcnJ1y2"},"source":["# **2. Dataset preparation**"]},{"cell_type":"code","metadata":{"id":"LvmlJIXT4xQk","executionInfo":{"status":"ok","timestamp":1631660245208,"user_tz":300,"elapsed":12,"user":{"displayName":"Jorge Cervera Perez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14520205137583916864"}}},"source":["# This function returns the generator of the form: (inputs, targets)               \n","def load_data(Train_df, idx, batch_size):\n","        \n","    parking_import = pandas.read_csv( Train_df + \"/groundtruth.txt\", skiprows=idx*batch_size, nrows=batch_size, delim_whitespace=True)\n","    parking_data = np.array(parking_import.values)\n","\n","    batch_images = []\n","    batch_labels = []  \n","\n","    for i in range (len(parking_data)):    \n","        image_name = parking_data[i][0]            \n","        image_name =  Train_df + \"/images/\" + image_name        \n","        img = load_img(image_name, color_mode=\"rgb\", target_size=(img_height, img_width), interpolation=\"nearest\")     \n","        img = img_to_array(img)        \n","        batch_images.append(img)         \n","        batch_labels.append(parking_data[i][1:])\n","    \n","    batch_images = np.array(batch_images)\n","    batch_images = batch_images / 255.0\n","    batch_labels = np.array(batch_labels).astype('float32')\n","    \n","    return (batch_images, batch_labels)           \n","\n","\n","def batch_generator(directory, batch_size, steps):    \n","    idx = 1\n","    while True:\n","        \n","        yield load_data(directory, idx-1, batch_size)## Yields data\n","        \n","        if idx < steps:\n","            idx+=1\n","        else:\n","            idx=1\n","            \n","### Generator objects for train and validation\n","my_training_batch_generator = batch_generator( route + \"/train\", batch_size, steps_per_epoch)\n","my_validation_batch_generator = batch_generator(route + \"/val\", batch_size, validation_steps)\n","\n","\n","   "],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F6QJcvRZJchd"},"source":["# **3. Model definition**"]},{"cell_type":"code","metadata":{"id":"ytMCPLRe577t","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1631660253843,"user_tz":300,"elapsed":8646,"user":{"displayName":"Jorge Cervera Perez","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14520205137583916864"}},"outputId":"f9673624-fd75-49d8-c60a-b83b60605ced"},"source":["##################### RESNET 50 MODEL #########################################\n","img_input = Input(shape=(img_height, img_width, img_channels)) \n","\n","\n","model = ResNet50( include_top=False, weights='imagenet',  input_tensor = img_input) \n","#model = keras.applications.Xception( include_top=False, weights='imagenet', input_tensor=img_input)\n","#model = keras.applications.NASNetLarge( include_top=False, weights='imagenet', input_tensor=img_input)\n","\n","x = model.output\n","\n","# FC layers\n","x = Flatten()(x)\n","x = Dense(1024)(x)\n","x = Activation('sigmoid')(x)\n","x = Dropout(0.5)(x)\n","\n","# Output dimension (empty place probability)\n","output_dim = 1\n","\n","x1 = Dense(output_dim)(x)\n","x1 = Activation('sigmoid', name='a1')(x1)\n","\n","x2 = Dense(output_dim)(x)\n","x2 = Activation('sigmoid', name='a2')(x2)\n","  \n","x3 = Dense(output_dim)(x)\n","x3 = Activation('sigmoid', name='a3')(x3)\n","  \n","x4 = Dense(output_dim)(x)\n","x4 = Activation('sigmoid', name='a4')(x4)\n","  \n","x5 = Dense(output_dim)(x)\n","x5 = Activation('sigmoid', name='a5')(x5)\n","  \n","x6 = Dense(output_dim)(x)\n","x6= Activation('sigmoid', name='a6')(x6)\n","  \n","x7 = Dense(output_dim)(x)\n","x7 = Activation('sigmoid', name='a7')(x7)\n","  \n","x8 = Dense(output_dim)(x)\n","x8 = Activation('sigmoid', name='a8')(x8)\n","  \n","x9 = Dense(output_dim)(x)\n","x9 = Activation('sigmoid', name='a9')(x9)\n","  \n","x10 = Dense(output_dim)(x)\n","x10 = Activation('sigmoid', name='a10')(x10)\n","  \n","x11 = Dense(output_dim)(x)\n","x11 = Activation('sigmoid', name='a11')(x11)\n","  \n","x12 = Dense(output_dim)(x)\n","x12 = Activation('sigmoid', name='a12')(x12)\n","  \n","x13= Dense(output_dim)(x)\n","x13 = Activation('sigmoid', name='a13')(x13)\n","  \n","x14 = Dense(output_dim)(x)\n","x14 = Activation('sigmoid', name='a14')(x14)\n","  \n","x15 = Dense(output_dim)(x)\n","x15 = Activation('sigmoid', name='a15')(x15)\n","  \n","x16 = Dense(output_dim)(x)\n","x16 = Activation('sigmoid', name='a16')(x16)\n","  \n","x17 = Dense(output_dim)(x)\n","x17 = Activation('sigmoid', name='a17')(x17)\n","  \n","x18 = Dense(output_dim)(x)\n","x18 = Activation('sigmoid', name='a18')(x18)\n","  \n","x19 = Dense(output_dim)(x)\n","x19 = Activation('sigmoid', name='a19')(x19)\n","  \n","x20 = Dense(output_dim)(x)\n","x20 = Activation('sigmoid', name='a20')(x20)\n","  \n","x21 = Dense(output_dim)(x)\n","x21 = Activation('sigmoid', name='a21')(x21)\n","\n","model = Model(inputs=[img_input], outputs= [x1,x2,x3,x4,x5,x6,x7,x8,x9,x10,x11,x12,x13,x14,x15,x16,x17,x18,x19,x20,x21])\n","\n","#print(model.summary())\n","#tf.keras.utils.plot_model( model, to_file=\"model.png\", show_shapes=False, show_dtype=False, show_layer_names=True, rankdir=\"TB\", expand_nested=False, dpi=96, layer_range=None,)\n","\n"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","94773248/94765736 [==============================] - 1s 0us/step\n","94781440/94765736 [==============================] - 1s 0us/step\n"]}]},{"cell_type":"markdown","metadata":{"id":"bvzC2Bm_yHpf"},"source":["# **4. Train model**"]},{"cell_type":"code","metadata":{"id":"ljDXNYeZDHzV"},"source":["optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, decay=1e-6)\n","\n","model.compile(loss='binary_crossentropy', \n","              optimizer=optimizer, \n","              metrics=['binary_accuracy'], \n","              loss_weights=np.ones((21,)).tolist() )\n","\n","checkpoint_filepath = '/content/drive/MyDrive/TFM/checkpoints/'\n","#metric = 'val_accuracy' #mode='max' \n","metric = 'val_loss' #mode='min'\n","model_checkpoint_callback = ModelCheckpoint( filepath=checkpoint_filepath,\n","                                              save_weights_only=True,\n","                                              monitor=metric,\n","                                              mode='min',\n","                                              save_best_only=True)\n","                          \n","history = model.fit( my_training_batch_generator,\n","                    epochs = nb_epoch,\n","                    steps_per_epoch = steps_per_epoch,\n","                    verbose = True, \n","                    validation_data = my_validation_batch_generator,\n","                    validation_steps = validation_steps,\n","                    callbacks=[model_checkpoint_callback])\n","\n","model.load_weights(checkpoint_filepath)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cdt2GowtAih4"},"source":["#Plot Loss\n","plt.plot(history.history['loss'], label='train loss')\n","plt.plot(history.history['val_loss'], label='validation loss')\n","\n","plt.xlabel('Epoch')\n","plt.ylabel('Loss')\n","plt.legend(loc='upper right')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y3myAFwYApF6"},"source":["#Plot results\n","#plt.plot(history.history['binary_accuracy'], label='binary_accuracy')\n","#plt.plot(history.history['val_binary_accuracy'], label = 'val_binary_accuracy')\n","#plt.xlabel('Epoch')\n","#plt.ylabel('Accuracy')\n","\n","#plt.legend(loc='lower right')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y-H_q8gDkyLG"},"source":["# **5. Test model**"]},{"cell_type":"code","metadata":{"id":"MAsMhXEo3WnD"},"source":["# Test evaluation\n","my_test_batch_generator = batch_generator( route + \"/test\", batch_size, steps_per_epoch)\n","\n","a = model.evaluate_generator( my_test_batch_generator, \n","                    test_steps, \n","                    max_queue_size = 10,\n","                    workers = 1)\n","\n","print(a)\n","\n","\n","\n","#read gt_test\n","#parking_test_import = pandas.read_csv( route + \"/test/groundtruth.txt\", delim_whitespace=True)\n","#parking_test_data = np.array(parking_test_import.values)\n","\n","#parking_test_images = []\n","#parking_test_labels = []\n","#for i in range (len(parking_test_data)):\n","#    image_name = parking_test_data[i][0]            \n","#    image_name =  route + '/test/images/' + image_name        \n","#    img = load_img(image_name, color_mode=\"rgb\", target_size=(img_height, img_width), interpolation=\"nearest\")     \n","#    img = img_to_array(img)        \n","#    parking_test_images.append(img) \n","\n","#    parking_test_label =  parking_test_data[i][1:]\n","#    parking_test_label = [np.array([i]).astype('float32').reshape((-1,1)) for i in parking_test_label]\n","#    parking_test_labels.append(parking_test_label)\n","\n","#test_images = np.array(parking_test_images)\n","#test_images = test_images / 255.0\n","\n","#parking_test_labels = np.array(parking_test_labels)\n","\n","\n","#test_loss, test_acc = model.evaluate(test_images,  parking_test_labels, verbose=2)\n","#print('Test accuracy: ',test_acc)\n","#parking_test_labels = np.asarray(parking_test_labels).astype('float32').reshape((-1,1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EVYQXfP6kur-"},"source":["# **6. Predict example**"]},{"cell_type":"code","metadata":{"id":"UDtblke7KkMJ"},"source":["img = load_img('/content/drive/MyDrive/TFM/data/merged_data/test/images/110GOPRO-GOPR4496.JPG'\n","               , color_mode=\"rgb\", \n","               target_size=(img_height, img_width), \n","               interpolation=\"nearest\")     \n","\n","img = img_to_array(img) \n","#Expand dimentions (batch = 1) for a single image since model expects a batch\n","img = np.expand_dims(img, axis=0)\n","print(img.shape) \n","\n","predictions = model.predict(img, batch_size=None)\n","print(predictions) \n","print(predictions[0]) \n","print(predictions[0][0]) \n","\n","parking_test_labels = np.asarray(parking_test_labels).astype('float32').reshape((-1,1))\n","\n","print(parking_test_labels)\n","\n"],"execution_count":null,"outputs":[]}]}